## This is a GAIT Project on Sign Language Interpreter- AI integrated
To Run:
pip install -r requirements.txt
python gestures.py

capturea-z.py is to capture the image for generating the custom dataset.
trained model is used in inference file to detect letters
Gestures file is for the sign language interpretation
Model is trained in traina-z.py and data processing is in dataseta-z.py


AI Models used:
OpenAI GPT 4o-mini(Text Generation), ElevenLabs(Text to Speech), MediaPipe(Handmarks detection).


External library ffmpeg added from https://ffmpeg.org/ - download the executable, add to the env path
